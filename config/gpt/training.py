from dataclasses import dataclass, field

from config import TrainingConfig, map_options

from .models import GPTConfig, gpt_options


@dataclass
class GPTTrainingConfig(TrainingConfig):
    gpt_config: GPTConfig = field(default_factory=GPTConfig)


# Training configuration options
options: dict[str, GPTTrainingConfig] = map_options(
    GPTTrainingConfig(
        name="shakespeare_64x4",
        gpt_config=gpt_options["ascii_64x4"],
        data_dir="data/shakespeare",
        eval_interval=250,
        eval_steps=100,
        batch_size=128,
        gradient_accumulation_steps=1,
        learning_rate=1e-3,
        warmup_steps=1000,
        max_steps=10000,
        decay_lr=True,
        min_lr=1e-5,
    ),
    GPTTrainingConfig(
        name="shakespeare_128x6",
        gpt_config=gpt_options["ascii_128x6"],
        data_dir="data/shakespeare",
        eval_interval=250,
        eval_steps=100,
        batch_size=128,
        gradient_accumulation_steps=1,
        learning_rate=1e-3,
        warmup_steps=300,
        max_steps=3000,
        decay_lr=True,
        min_lr=1e-4,
    ),
    GPTTrainingConfig(
        name="stories_32x4",
        gpt_config=gpt_options["tiktoken_32x4"],
        data_dir="data/simple_stories_10m",
        eval_interval=250,
        eval_steps=100,
        batch_size=128,
        gradient_accumulation_steps=8,
        learning_rate=1e-3,
        max_steps=5000,
    ),
    GPTTrainingConfig(
        name="stories_256x4",
        gpt_config=gpt_options["tiktoken_256x4"],
        data_dir="data/simple_stories",
        eval_interval=250,
        eval_steps=100,
        batch_size=512,
        gradient_accumulation_steps=8,
        learning_rate=1e-3,
        max_steps=10000,
        decay_lr=True,
        min_lr=1e-4,
    ),
    GPTTrainingConfig(
        name="integer_1000_128x4",
        gpt_config=gpt_options["integer_1000_128x4"],
        data_dir="data/integer_data",
        eval_interval=100,
        eval_steps=50,
        batch_size=64,
        gradient_accumulation_steps=2,
        learning_rate=3e-4,
        warmup_steps=500,
        max_steps=5000,
        decay_lr=True,
        min_lr=1e-5,
    ),
    GPTTrainingConfig(
        name="integer_10000_256x6",
        gpt_config=gpt_options["integer_10000_256x6"],
        data_dir="data/integer_data",
        eval_interval=250,
        eval_steps=100,
        batch_size=128,
        gradient_accumulation_steps=4,
        learning_rate=1e-3,
        warmup_steps=1000,
        max_steps=10000,
        decay_lr=True,
        min_lr=1e-4,
    ),
    GPTTrainingConfig(
        name="integer_100_64x1",
        gpt_config=gpt_options["integer_100_64x1"],
        data_dir="data/integer_data/example_json_output",
        eval_interval=50,
        eval_steps=20,
        batch_size=16,
        gradient_accumulation_steps=1,
        learning_rate=3e-4,
        warmup_steps=100,
        max_steps=1000,
        decay_lr=True,
        min_lr=1e-5,
    ),
    GPTTrainingConfig(
        name="mess3_64x1",
        gpt_config=gpt_options["mess3_64x1"],
        data_dir="data/integer_data/mess3_json_output",
        eval_interval=50,
        eval_steps=20,
        batch_size=128,
        gradient_accumulation_steps=1,
        learning_rate=1e-4,
        warmup_steps=0,
        max_steps=12000,
        decay_lr=False,
        min_lr=1e-5,
        weight_decay=0.0,
    ),
)
